# LSTM 시퀀스 모델링을 위한 데이터 분석 보고서

**작성일:** 2025-12-11
**목적:** K리그 패스 좌표 예측 - LSTM 모델 설계 기초 데이터 분석

---

## 1. 데이터 개요

### 1.1 기본 통계

| 항목 | 값 | 비고 |
|------|------|------|
| **전체 행(액션)** | 356,721개 | - |
| **Pass 액션** | 178,582개 | 50% |
| **고유 에피소드** | 15,435개 | 게임 진행 단위 |
| **고유 게임** | ~500개 추정 | - |

### 1.2 데이터 구성

```
game_id → period_id → episode_id → [Pass, Carry, Duel, ...]
                               ↓
                        time_seconds (순서 지정)
                        (start_x, start_y) → (end_x, end_y)
```

---

## 2. 에피소드별 패스 개수 분포 (LSTM 시퀀스 적합도 핵심)

### 2.1 통계

| 지표 | 값 | 해석 |
|------|------|------|
| **최소** | 1 | 매우 짧은 에피소드 존재 |
| **최대** | 148 | 매우 긴 에피소드 가능 |
| **평균** | 11.57 | 일반적 에피소드 = 12 Pass |
| **중앙값** | 8 | 50% 에피소드 = 8 Pass 이하 |
| **표준편차** | 11.79 | 높은 분산 (다양한 길이) |
| **Q1 (25%)** | 3 | 25% 에피소드 = 3 Pass 이하 |
| **Q3 (75%)** | 16 | 75% 에피소드 = 16 Pass 이하 |

### 2.2 에피소드 길이 분포

**분포 형태:** 오른쪽으로 긴꼬리 (Long-tailed Distribution)

```
Pass/Episode:  1    2    3    4    5    6    7    8    9   10
Episode Count: 1486 1352 1101 993  924  830  790  705  638 599
Percentage:    9.6% 8.8% 7.1% 6.4% 6.0% 5.4% 5.1% 4.6% 4.1% 3.9%
```

**의미:**
- 약 10% 에피소드는 1-2 Pass로 매우 짧음
- 약 30% 에피소드는 1-3 Pass로 시퀀스 학습 불가
- 약 62% 에피소드는 6 Pass 이상 (시퀀스 학습 가능)

---

## 3. 시퀀스 길이 5 기반 샘플 수 분석

### 3.1 핵심 결과

| 항목 | 값 | |
|------|------|------|
| **사용 가능 에피소드** | 9,579 / 15,435 | **62%** |
| **사용 가능 샘플** | 114,602개 | **(5개 입력 + 1개 타겟)** |
| **사용 데이터(Pass)** | 162,497개 | **90.99%** |
| **폐기 데이터** | 16,085개 | **9.01%** (Pass < 6인 에피소드) |

### 3.2 시퀀스 길이별 비교

| Seq Len | 사용 에피소드 | 샘플 수 | 데이터 활용률 | 패턴 복잡도 |
|---------|----------|--------|-----------|---------|
| **3** | 11,496 | 136,601 | 95% | 낮음 |
| **4** | 10,503 | 125,105 | 93% | 중간 |
| **5** | 9,579 | 114,602 | 91% | **중간** |
| **6** | 8,749 | 105,023 | 88% | 높음 |
| **7** | 7,959 | 96,274 | 86% | 높음 |
| **10** | 6,017 | 74,445 | 78% | 매우 높음 |

### 3.3 권장 선택

**최적 선택: 시퀀스 길이 = 5**

**이유:**
1. 충분한 샘플 수 (114,602개 > 100,000개 기준)
2. 데이터 손실 최소 (약 10%)
3. 학습 가능한 패턴 복잡도 (3-4 Pass 패턴)
4. 계산 복잡도와 성능의 균형

**대안:**
- **Seq_len=3:** 최대 데이터 활용 (95%), 단순 패턴만 학습
- **Seq_len=7:** 복잡한 패턴 학습, 데이터 손실 증가 (14%)

---

## 4. 시간 간격(time_diff) 분포 분석

### 4.1 시간 간격 통계

| 지표 | 값 | 의미 |
|------|------|------|
| **개수** | 163,147 | Pass 간 간격 |
| **최소** | 0.000초 | 동시 실행 액션 |
| **최대** | 655.822초 | 에피소드 경계 (이상치) |
| **평균** | 3.764초 | 전형적 Pass 간격 |
| **중앙값** | 2.956초 | 50% Pass는 3초 내 발생 |
| **표준편차** | 4.837초 | 높은 변동성 |

### 4.2 백분위 분포 (Action Timing)

```
1%ile:    0.666초 ┐
5%ile:    0.941초 │
10%ile:   1.233초 ├─ 빠른 패스 (68% 이내)
25%ile:   1.967초 │
50%ile:   2.956초 ┤ 중간값
75%ile:   4.500초 │
90%ile:   6.667초 ├─ 느린 패스
95%ile:   8.466초 │
99%ile:  14.433초 ┘
```

### 4.3 시간 정보 활용 방안

**방안 1: 시간 정규화 (권장)**
```python
# log 스케일 정규화 (이상치 감소)
time_diff_norm = np.log(1 + time_diff / time_diff.median())
# 결과: -∞ ~ 0.69 범위 (감시 가능)
```

**방안 2: Quantile 기반 클리핑**
```python
# 95분위(8.5초) 이상을 이상치로 처리
time_diff_clipped = np.clip(time_diff, 0, np.percentile(time_diff, 95))
# 결과: 0 ~ 8.5초 범위
```

**방안 3: 카테고리화**
```python
time_category = [
    'fast' if t < 2.0 else
    'normal' if t < 5.0 else
    'slow'
]
```

### 4.4 LSTM에서의 활용

**입력 피처로 추가할 경우:**
- 다음 Pass까지의 시간 정보
- 패스 성공률과 상관관계 검토
- 순환 구조: 시간 → 다음 Pass 위치 예측

---

## 5. 좌표 범위 분석 (필드 공간 이해)

### 5.1 필드 좌표계

```
풋볼 필드 (표준 K리그):
┌─────────────────────────────────┐
│ (0, 68)                 (105, 68)│  Y축: 0 ~ 68
│                                 │  X축: 0 ~ 105
│        필드 전개 공간             │
│                                 │
│ (0, 0)                   (105, 0)│
└─────────────────────────────────┘

정규화 범위:
X: [0, 105] → [0, 1] (÷ 105)
Y: [0, 68] → [0, 1] (÷ 68)
```

### 5.2 좌표별 통계

#### Start Position (패스 시작점)

| 좌표 | 최소 | 최대 | 평균 | 표준편차 | 분포 |
|------|------|------|------|---------|------|
| **start_x** | 0.00 | 105.00 | 47.26 | 23.81 | 균등분포 |
| **start_y** | 0.00 | 68.00 | 34.15 | 19.80 | 균등분포 |

#### End Position (패스 목표점)

| 좌표 | 최소 | 최대 | 평균 | 표준편차 | 분포 |
|------|------|------|------|---------|------|
| **end_x** | 0.00 | 105.00 | 51.04 | 24.29 | 약간 전방향 |
| **end_y** | 0.00 | 68.00 | 34.13 | 19.72 | 중앙 집중 |

### 5.3 해석

**Start와 End의 차이:**
- `end_x` 평균 > `start_x` 평균 (51.04 vs 47.26)
  → **전방향 패스 경향** (공격 쪽으로)
- `end_y` ≈ `start_y` (34.13 vs 34.15)
  → **측면 패스 균형** (좌우 대칭)

**LSTM 입력으로의 의미:**
- 4차원 벡터 충분 (start_x, start_y, end_x, end_y)
- 좌표 범위가 완전히 커버됨 (모든 필드 구간 사용)
- 정규화 필수 (범위 [0, 1]로 정규화)

---

## 6. 파생 피처 분석

### 6.1 Pass Distance (패스 거리)

```python
distance = sqrt((end_x - start_x)^2 + (end_y - start_y)^2)
```

| 지표 | 값 | 의미 |
|------|------|------|
| **최소** | 0.00m | 제자리 패스 (거의 없음) |
| **최대** | 93.90m | 필드 전체 거리 |
| **평균** | 16.84m | 전형적 패스 거리 |
| **분포** | 왼쪽 치우침 | 대부분 단거리 패스 |

### 6.2 Pass Angle (패스 방향)

```python
angle = arctan2(end_y - start_y, end_x - start_x) * 180/π
```

| 지표 | 값 | 의미 |
|------|------|------|
| **최소** | -180도 | 좌측 후방 |
| **최대** | 180도 | 우측 후방 |
| **평균** | -0.64도 | 거의 수평 (약간 좌측) |
| **분포** | 중앙 집중 | 전방향 패스 비슷 |

### 6.3 LSTM에서의 활용

**옵션 1: 원본 좌표 사용**
```
Input: [start_x, start_y, end_x, end_y]
장점: 직관적, 좌표 공간 정보 유지
```

**옵션 2: 파생 피처 사용**
```
Input: [distance, angle, time_diff, is_successful_prev]
장점: 특성 공학, 상대적 패턴 강조
```

**옵션 3: 혼합**
```
Input: [start_x, start_y, end_x, end_y, distance, time_diff]
장점: 다양한 관점의 정보
```

---

## 7. Pass 결과 분포 (클래스 불균형)

### 7.1 분포

| 결과 | 개수 | 비율 | 의미 |
|------|------|------|------|
| **Successful** | 154,195 | 86.34% | 대다수 |
| **Unsuccessful** | 24,387 | 13.66% | 소수 |

### 7.2 불균형 처리 방법

**방법 1: Class Weight (권장)**
```python
# 불균형 가중치 적용
class_weight = {
    0: 1.0,  # Unsuccessful
    1: 0.16  # Successful (= 13.66% / 86.34%)
}
```

**방법 2: Focal Loss**
```python
# 어려운 샘플에 더 큰 가중치
focal_loss = -α * (1 - p_t)^γ * log(p_t)
```

**방법 3: Under/Over Sampling**
```python
# Unsuccessful 샘플 오버샘플링 또는
# Successful 샘플 언더샘플링
```

**추천:** **Class Weight 사용** (정보 손실 없음)

---

## 8. LSTM 모델 설계 권장사항

### 8.1 기본 구조

```
Input: (batch_size, seq_length=5, features=4)
  └─ 정규화 좌표: [start_x/105, start_y/68, end_x/105, end_y/68]

LSTM Layer 1: 64 units, return_sequences=True
  └─ Dropout: 0.2
  └─ 첫 번째 시퀀스 패턴 추출

LSTM Layer 2: 32 units, return_sequences=False
  └─ Dropout: 0.2
  └─ 종합 패턴 특성 추출

Dense Layer 1: 16 units, ReLU
  └─ 비선형 변환

Dense Layer 2: 8 units, ReLU
  └─ 최종 특성

Output Layer: 2 units, Softmax
  └─ [P(Successful), P(Unsuccessful)]
```

### 8.2 고급 변형

**변형 1: 더 깊은 모델**
```
LSTM(128) → LSTM(64) → LSTM(32) → Dense(16) → Dense(8) → Output
```

**변형 2: 양방향 LSTM (Bidirectional)**
```
입력 방향: Pass 1 → 2 → 3 → 4 → 5
역방향: Pass 5 → 4 → 3 → 2 → 1
→ 양쪽 문맥 학습
```

**변형 3: 시간 정보 포함**
```
Input: [start_x, start_y, end_x, end_y, log(time_diff+1)]
LSTM(128) → ... → Output
```

### 8.3 학습 파라미터

| 파라미터 | 권장값 | 범위 |
|---------|--------|------|
| **배치 크기** | 64 | 32-128 |
| **학습률** | 0.001 | 0.0001-0.01 |
| **드롭아웃** | 0.2 | 0.1-0.3 |
| **에포크** | 50-100 | 50-200 |
| **Early Stopping** | patience=10 | - |

---

## 9. 데이터 전처리 체크리스트

### 9.1 필수 전처리

- [ ] **Null/NaN 제거**: 좌표 값 검증
- [ ] **좌표 정규화**: [0,1] 범위로 스케일링
- [ ] **시간 간격 처리**:
  - [ ] 동일 시간(0초) 처리 (4개 건)
  - [ ] 이상치(>95분위) 클리핑 또는 제거
- [ ] **에피소드 필터링**: Pass >= 6개인 에피소드만 추출
- [ ] **시간 순서 검증**: 각 에피소드 내 정렬 확인

### 9.2 선택적 전처리

- [ ] **파생 피처 생성**:
  - [ ] distance = sqrt((end_x-start_x)^2 + (end_y-start_y)^2)
  - [ ] angle = arctan2(end_y-start_y, end_x-start_x)
- [ ] **Pass 결과 인코딩**: Successful=1, Unsuccessful=0
- [ ] **클래스 가중치 계산**: class_weight = {0: 1.0, 1: 0.16}

### 9.3 데이터 검증

- [ ] **통계 검증**: Mean/Std 정상 범위 확인
- [ ] **분포 검증**: 각 피처의 히스토그램 확인
- [ ] **시계열 순서**: 에피소드별 시간 순서 확인
- [ ] **메모리 확인**: 114,602 샘플 * 5 seq_len * 4 features = 2.3MB (충분)

---

## 10. 최종 결론 및 권장사항

### 10.1 데이터 적합도

| 항목 | 평가 | 근거 |
|------|------|------|
| **시퀀스 학습** | **✓ 우수** | 114,602 샘플 (충분) |
| **시간 정보** | **✓ 충분** | Pass 간 명확한 시간 순서 |
| **좌표 정보** | **✓ 완전** | 4개 좌표 (start, end) |
| **클래스 분포** | **⚠ 주의** | 86% vs 14% (불균형) |
| **데이터 품질** | **✓ 높음** | Null 없음, 범위 명확 |

**결론: LSTM 모델링에 매우 적합합니다!**

### 10.2 단계별 접근

**Phase 1: 기본 모델 (Baseline)**
```python
# LSTM(64) → LSTM(32) → Dense(16) → Output(2)
# Seq_len=5, Features=4 (정규화 좌표)
# 기대 성능: 85-88% Accuracy
```

**Phase 2: 개선 모델**
```python
# 옵션 1: 더 깊은 LSTM 추가
# 옵션 2: 양방향 LSTM 적용
# 옵션 3: 시간 정보 추가
# 기대 성능: 88-91% Accuracy
```

**Phase 3: 고급 모델**
```python
# 옵션 1: 멀티태스크 (Pass 성공 + 좌표 예측)
# 옵션 2: 어텐션 메커니즘 추가
# 옵션 3: 하이브리드 (LSTM + CNN)
# 기대 성능: 91%+ Accuracy
```

### 10.3 즉시 실행 항목

1. **데이터 전처리 스크립트 작성**
   - 에피소드 필터링 (Pass >= 6)
   - 좌표 정규화
   - 시간 간격 처리

2. **기본 LSTM 모델 구현**
   - TensorFlow/PyTorch 선택
   - 데이터 로더 작성
   - 학습 루프 구성

3. **성능 평가 설정**
   - Accuracy, Precision, Recall, F1-Score
   - Confusion Matrix 시각화
   - 오류 분석

---

## 11. 데이터 요약

```
총 데이터량
├─ 전체 액션: 356,721개
├─ Pass 액션: 178,582개 (50%)
└─ 사용 가능: 162,497개 (91%)

시퀀스 구성
├─ 총 에피소드: 15,435개
├─ 사용 에피소드: 9,579개 (62%)
└─ LSTM 샘플: 114,602개 ← 충분

필드 좌표
├─ X 범위: [0, 105] → 정규화 [0, 1]
├─ Y 범위: [0, 68] → 정규화 [0, 1]
└─ 정규화 필수

시간 정보
├─ Pass 간 평균: 3.764초
├─ Pass 간 중앙값: 2.956초
└─ 이상치: 655초 (에피소드 경계)

클래스 분포
├─ Successful: 86% (154,195개)
├─ Unsuccessful: 14% (24,387개)
└─ Class Weight 적용 권장
```

---

**작성자:** 데이터 분석팀
**최종 승인:** 2025-12-11
**다음 단계:** LSTM 모델 구현 및 훈련
