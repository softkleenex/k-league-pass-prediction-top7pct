"""
CatBoost Hyperparameter Tuning (ë¡œì»¬ ì‹¤í—˜)

Ultrathink 2025-12-16:
- Batch 1: CV 15.79 Â± 0.27 (16 features)
- Tuning: iterations, depth, learning_rate
- ëª©í‘œ: CV 15.65-15.70 (â–³0.1-0.15)

âš ï¸ ë¡œì»¬ ì‹¤í—˜ë§Œ! ì œì¶œ ì•ˆ í•¨!
"""

import sys
sys.path.append('../../utils')

import pandas as pd
import numpy as np
import catboost as cb
import time
import warnings
warnings.filterwarnings('ignore')

from fast_experiment_v2 import FastExperimentV2

print("=" * 80)
print("CatBoost Hyperparameter Tuning (ë¡œì»¬ ì‹¤í—˜)")
print("=" * 80)
print("\nBatch 1 Baseline: CV 15.79 Â± 0.27")
print("ëª©í‘œ: CV 15.65-15.70 (â–³0.1-0.15)")
print("\nâš ï¸ ë¡œì»¬ ì‹¤í—˜ë§Œ! ì œì¶œ ì•ˆ í•¨!")

# =============================================================================
# Setup
# =============================================================================
exp = FastExperimentV2(sample_frac=1.0, n_folds=5, random_state=42)

# Load & Features
train_df = exp.load_data(train_path='../../../train.csv', sample=False)
train_df = exp.create_features(train_df)
X, y, groups, feature_cols = exp.prepare_data(train_df)

# =============================================================================
# Grid Search
# =============================================================================
print("\n" + "=" * 80)
print("Grid Search")
print("=" * 80)

# Parameter grid (ê°„ë‹¨í•˜ê²Œ)
param_grid = {
    'iterations': [150, 200, 300],
    'depth': [7, 8],
    'learning_rate': [0.05, 0.08]
}

print(f"\níŒŒë¼ë¯¸í„° ì¡°í•©:")
print(f"  iterations: {param_grid['iterations']}")
print(f"  depth: {param_grid['depth']}")
print(f"  learning_rate: {param_grid['learning_rate']}")
print(f"  ì´ ì¡°í•©: {len(param_grid['iterations']) * len(param_grid['depth']) * len(param_grid['learning_rate'])}ê°œ")

baseline_params = {
    'subsample': 0.8,
    'random_state': 42,
    'verbose': 0
}

results = []
best_cv = float('inf')
best_params = None

total_combinations = (
    len(param_grid['iterations']) *
    len(param_grid['depth']) *
    len(param_grid['learning_rate'])
)

print(f"\nì‹œì‘...")
start_all = time.time()

combination = 0
for iterations in param_grid['iterations']:
    for depth in param_grid['depth']:
        for lr in param_grid['learning_rate']:
            combination += 1

            params = {
                **baseline_params,
                'iterations': iterations,
                'depth': depth,
                'learning_rate': lr
            }

            print(f"\n[{combination}/{total_combinations}] iter={iterations}, depth={depth}, lr={lr}")

            start = time.time()

            model_x = cb.CatBoostRegressor(**params)
            model_y = cb.CatBoostRegressor(**params)

            cv_mean, cv_std, fold_scores = exp.run_cv(
                model_x, model_y, X, y, groups,
                model_name=f'CatBoost (iter={iterations}, depth={depth}, lr={lr})'
            )

            runtime = time.time() - start

            results.append({
                'iterations': iterations,
                'depth': depth,
                'learning_rate': lr,
                'cv_mean': cv_mean,
                'cv_std': cv_std,
                'runtime': runtime
            })

            if cv_mean < best_cv:
                best_cv = cv_mean
                best_params = params
                print(f"  âœ… New Best! CV {cv_mean:.4f}")

            print(f"  Runtime: {runtime:.1f}s")

total_time = time.time() - start_all

# =============================================================================
# ê²°ê³¼ ìš”ì•½
# =============================================================================
print("\n" + "=" * 80)
print("íŠœë‹ ê²°ê³¼")
print("=" * 80)

# Sort by CV
results_sorted = sorted(results, key=lambda x: x['cv_mean'])

print(f"\n{'Rank':<5} {'Iter':<6} {'Depth':<6} {'LR':<6} {'CV':<18} {'Runtime':<10}")
print("-" * 65)

for i, r in enumerate(results_sorted[:10], 1):  # Top 10
    marker = "â­" if i == 1 else ""
    print(f"{i:<5} {r['iterations']:<6} {r['depth']:<6} {r['learning_rate']:<6.2f} "
          f"{r['cv_mean']:.4f}Â±{r['cv_std']:.4f}  {r['runtime']:<10.1f}s {marker}")

# Best result
print(f"\n" + "=" * 80)
print("ìµœì  íŒŒë¼ë¯¸í„°")
print("=" * 80)

baseline_cv = 15.79
improvement = baseline_cv - best_cv

print(f"\n  Baseline: {baseline_cv:.4f}")
print(f"  Best:     {best_cv:.4f}")
print(f"  ê°œì„ :     {improvement:+.4f}ì ")

print(f"\n  ìµœì  íŒŒë¼ë¯¸í„°:")
for k, v in best_params.items():
    print(f"    {k}: {v}")

print(f"\n  ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}s")

# ëˆ„ì  ê°œì„ 
print(f"\n" + "=" * 80)
print("ëˆ„ì  ê°œì„  ì¶”ì ")
print("=" * 80)

baseline_original = 16.04
cumulative = baseline_original - best_cv

print(f"\nBaseline (Zone 6x6): {baseline_original:.2f}")
print(f"Batch 1:             {baseline_cv:.2f} (â–³{baseline_original - baseline_cv:+.2f})")
print(f"Batch 1 + Tuning:    {best_cv:.2f} (â–³{baseline_original - best_cv:+.2f})")
print(f"\nëˆ„ì  ê°œì„ : {cumulative:.2f}ì ")

if improvement > 0:
    print(f"\nâœ… Tuning ì„±ê³µ! {improvement:.2f}ì  ê°œì„ ")

    if cumulative >= 0.3:
        print(f"\nğŸ¯ ì œì¶œ ê¸°ì¤€ ë‹¬ì„±! (â–³0.3 ì´ìƒ)")
        print(f"   Public ì˜ˆìƒ: {best_cv + 0.35:.2f} (Gap 0.35 ê°€ì •)")
        print(f"   vs í˜„ì¬ Best (16.14): {16.14 - (best_cv + 0.35):.2f}ì  ê°œì„ ")
        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        print(f"  1. Best íŒŒë¼ë¯¸í„°ë¡œ ì¬í•™ìŠµ")
        print(f"  2. Test ì˜ˆì¸¡")
        print(f"  3. ì œì¶œ!")
    else:
        print(f"\nâ³ ì œì¶œ ê¸°ì¤€ ë¯¸ë‹¬ (â–³0.3 í•„ìš”, í˜„ì¬ â–³{cumulative:.2f})")
        print(f"   ì¶”ê°€ í•„ìš”: {0.3 - cumulative:.2f}ì ")
        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        print(f"  1. Ensemble ì‹œë„")
        print(f"  2. ë˜ëŠ” ë” ë§ì€ íŒŒë¼ë¯¸í„° íƒìƒ‰")
else:
    print(f"\nâš ï¸ Tuning íš¨ê³¼ ì—†ìŒ ({improvement:.2f}ì )")

# Save best params
import json
from pathlib import Path

best_result = {
    'params': best_params,
    'cv_mean': float(best_cv),
    'cv_std': float(results_sorted[0]['cv_std']),
    'improvement': float(improvement),
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

output_file = Path('../../../logs/best_params.json')
output_file.parent.mkdir(exist_ok=True)

with open(output_file, 'w') as f:
    json.dump(best_result, f, indent=2, ensure_ascii=False)

print(f"\nâœ… ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥: {output_file}")

print("\n" + "=" * 80)
print("âœ… Hyperparameter Tuning ì™„ë£Œ!")
print("=" * 80)
