"""
Phase 1-A ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ê°•í™” ë²„ì „)

ëª©í‘œ:
  1. CV ê²°ê³¼ ë¡œë“œ ë° ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµ ë¶„ì„
  2. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ (t-test, ì‹ ë¢°êµ¬ê°„)
  3. ì‹ ê·œ 5ê°œ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
  4. ì œì¶œ ê²°ì • ê¸°ì¤€ í‰ê°€ ë° ê¶Œì¥ì‚¬í•­

CV ë¹„êµ ê¸°ì¤€:
  - ê¸°ì¡´ catboost_tuned (exp_028): CV 15.60 Â± 0.27
  - Phase 1-A: cv_results.jsonì—ì„œ ë¡œë“œ
  - ê°œì„  ëª©í‘œ: CV < 15.50 (0.10ì  ì´ìƒ ê°œì„ )

ì œì¶œ ê²°ì • ê¸°ì¤€:
  - CV < 15.5: ğŸš€ ê°•ë ¥ ì¶”ì²œ (ëª©í‘œ ë‹¬ì„±!)
  - CV 15.5-15.6: âœ… ì¶”ì²œ (ê°œì„  í™•ì¸)
  - CV > 15.6: âš ï¸ ì¬ê²€í†  í•„ìš”

ì‘ì„±ì¼: 2025-12-17
ì‘ì„±ì: Data Analysis Team
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from scipy import stats
from typing import Dict, Tuple, List, Optional


class Phase1AResultsAnalyzer:
    """Phase 1-A ê²°ê³¼ ì¢…í•© ë¶„ì„ê¸°"""

    def __init__(self, results_dir: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            results_dir: ì‹¤í—˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜)
        """
        if results_dir is None:
            results_dir = Path(__file__).parent
        else:
            results_dir = Path(results_dir)

        self.results_dir = results_dir
        self.cv_results_file = results_dir / 'cv_results.json'

        # ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (ë² ì´ìŠ¤ë¼ì¸)
        self.baseline = {
            'name': 'catboost_tuned (exp_028)',
            'cv_mean': 15.60,
            'cv_std': 0.27,
            'public_score': 15.8420,
            'gap': 0.24,
            'cv_folds': np.array([15.65, 15.60, 15.55]),
            'n_folds': 3
        }

        # ì‹ ê·œ í”¼ì²˜ ì •ì˜
        self.new_features_info = {
            'is_final_team': {
                'importance_score': 5.0,
                'description': 'ê³µê²©ê¶Œ í”Œë˜ê·¸ (ê³¨ ë„£ì€ íŒ€ì˜ íŒ¨ìŠ¤ ì—¬ë¶€)',
                'business_value': 'ê³µê²©/ìˆ˜ë¹„ ë§¥ë½ ëª…í™•íˆ êµ¬ë¶„ ê°€ëŠ¥',
                'expected_contribution': 0.05  # ì¤‘ê°„ê°’
            },
            'team_possession_pct': {
                'importance_score': 4.0,
                'description': 'ì ìœ ìœ¨ (ìµœê·¼ 20ê°œ íŒ¨ìŠ¤ ì¤‘ ìš°ë¦¬ íŒ€ ë¹„ìœ¨)',
                'business_value': 'ì¡°ì§ì  ê³µê²© vs ì—­ìŠµ ì „ìˆ  êµ¬ë¶„',
                'expected_contribution': 0.045
            },
            'team_switches': {
                'importance_score': 3.0,
                'description': 'ê³µìˆ˜ ì „í™˜ ëˆ„ì  íšŸìˆ˜ (ê²½ê¸° ì§„í–‰ ìƒí™©)',
                'business_value': 'ê²½ê¸° í˜¼ë€ë„/í…œí¬ íŒŒì•…',
                'expected_contribution': 0.03
            },
            'game_clock_min': {
                'importance_score': 3.0,
                'description': 'ê²½ê¸° ì‹œì‘ë¶€í„° ê²½ê³¼ ì‹œê°„ (0-90ë¶„+)',
                'business_value': 'ì „ë°˜/í›„ë°˜ êµ¬ë¶„ ì œê±°, ì—°ì† ì‹œê°„ í™œìš©',
                'expected_contribution': 0.02
            },
            'final_poss_len': {
                'importance_score': 2.0,
                'description': 'í˜„ì¬ ì—°ì† ìš°ë¦¬ íŒ€ ì†Œìœ  íŒ¨ìŠ¤ ìˆ˜',
                'business_value': 'ë¹Œë“œì—… vs ë‹¨ë°œì„± ê³µê²© êµ¬ë¶„',
                'expected_contribution': 0.015
            }
        }

        self.phase1a_results = None
        self.comprehensive_analysis = None

    # ========================================================================
    # 1. ë°ì´í„° ë¡œë“œ
    # ========================================================================

    def load_cv_results(self) -> bool:
        """CV ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ"""
        print(f"\n{'='*80}")
        print("1. CV ê²°ê³¼ ë¡œë“œ")
        print(f"{'='*80}")

        if not self.cv_results_file.exists():
            print(f"  âŒ ì˜¤ë¥˜: {self.cv_results_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"  ì‹¤í—˜ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”:")
            print(f"    python code/utils/fast_experiment_phase1a.py --run")
            return False

        try:
            with open(self.cv_results_file, 'r') as f:
                self.phase1a_results = json.load(f)

            print(f"  âœ“ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            print(f"    ê²½ë¡œ: {self.cv_results_file}")
            print(f"    íƒ€ì„ìŠ¤íƒí”„: {self.phase1a_results.get('timestamp', 'N/A')}")
            print(f"    ëª¨ë¸: {self.phase1a_results.get('model', 'N/A')}")
            print(f"    ì´ í”¼ì²˜: {self.phase1a_results.get('features', {}).get('total', 'N/A')} ê°œ")

            return True

        except Exception as e:
            print(f"  âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    # ========================================================================
    # 2. CV ë¹„êµ ë¶„ì„
    # ========================================================================

    def compare_cv_performance(self) -> Dict:
        """ê¸°ì¡´ ëª¨ë¸ê³¼ Phase 1-Aì˜ CV ì„±ëŠ¥ ë¹„êµ"""
        if self.phase1a_results is None:
            print("  âŒ CV ê²°ê³¼ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {}

        print(f"\n{'='*80}")
        print("2. CV ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
        print(f"{'='*80}")

        baseline_mean = self.baseline['cv_mean']
        baseline_std = self.baseline['cv_std']
        phase1a_mean = self.phase1a_results['cv_mean']
        phase1a_std = self.phase1a_results['cv_std']
        phase1a_folds = np.array(self.phase1a_results['cv_folds'])

        # ê°œì„ í­ ê³„ì‚° (ì ˆëŒ€ê°’, ë°±ë¶„ìœ¨)
        cv_improvement = baseline_mean - phase1a_mean  # ìŒìˆ˜ = ì•…í™”
        cv_improvement_pct = (cv_improvement / baseline_mean) * 100
        std_improvement = baseline_std - phase1a_std   # ì•ˆì •ì„±: ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ

        print(f"\n  ê¸°ì¡´ ëª¨ë¸ (ë² ì´ìŠ¤ë¼ì¸):")
        print(f"    ì´ë¦„: {self.baseline['name']}")
        print(f"    CV Mean: {baseline_mean:.4f} Â± {baseline_std:.4f}")
        print(f"    Public: {self.baseline['public_score']:.4f} (Gap: {self.baseline['gap']:.2f})")
        print(f"    Foldë³„:")
        for i, fold_val in enumerate(self.baseline['cv_folds'], 1):
            print(f"      Fold {i}: {fold_val:.4f}")

        print(f"\n  Phase 1-A:")
        print(f"    CV Mean: {phase1a_mean:.4f} Â± {phase1a_std:.4f}")
        print(f"    Foldë³„:")
        for i, fold_val in enumerate(phase1a_folds, 1):
            print(f"      Fold {i}: {fold_val:.4f}")

        print(f"\n  ì„±ëŠ¥ ê°œì„ í­:")
        print(f"    CV ê°œì„ : {cv_improvement:+.4f} (ìŒìˆ˜ = ê°œì„ )")
        print(f"    ê°œì„ ë¥ : {cv_improvement_pct:+.2f}%")
        print(f"    ì•ˆì •ì„± ê°œì„ : {std_improvement:+.4f} (ì–‘ìˆ˜ = ì•ˆì •ì„± í–¥ìƒ)")
        print(f"    ì•ˆì •ì„± í–¥ìƒ: {(std_improvement/baseline_std)*100:+.1f}%")

        # Foldë³„ ê°œì„  ë¶„ì„
        print(f"\n  Foldë³„ ê°œì„  ë¶„ì„:")
        baseline_folds = self.baseline['cv_folds']
        fold_improvements = baseline_folds - phase1a_folds
        for i, (imp, base, phase1a) in enumerate(zip(fold_improvements, baseline_folds, phase1a_folds), 1):
            emoji = "âœ…" if imp > 0 else "âŒ"
            print(f"    Fold {i}: {base:.4f} â†’ {phase1a:.4f} ({imp:+.4f}) {emoji}")

        # ì¢…í•© í‰ê°€
        if cv_improvement > 0.10:
            evaluation = "ğŸš€ ê°•ë ¥ ì¶”ì²œ (0.10ì  ì´ìƒ ê°œì„ )"
        elif cv_improvement > 0.0:
            evaluation = "âœ… ì¡°ê±´ë¶€ ì¶”ì²œ (ì•½í•œ ê°œì„ )"
        elif cv_improvement >= -0.05:
            evaluation = "âš ï¸ ì¤‘ë¦½ (ë¯¸ë¯¸í•œ ì•…í™”)"
        else:
            evaluation = "âŒ ì¬ê²€í†  í•„ìš” (ëª…ë°±í•œ ì•…í™”)"

        print(f"\n  ì¢…í•© í‰ê°€: {evaluation}")

        comparison_result = {
            'baseline_cv_mean': baseline_mean,
            'baseline_cv_std': baseline_std,
            'phase1a_cv_mean': phase1a_mean,
            'phase1a_cv_std': phase1a_std,
            'cv_improvement': cv_improvement,
            'cv_improvement_pct': cv_improvement_pct,
            'std_improvement': std_improvement,
            'fold_improvements': fold_improvements.tolist(),
            'evaluation': evaluation
        }

        return comparison_result

    # ========================================================================
    # 3. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
    # ========================================================================

    def statistical_significance_test(self, cv_comparison: Dict) -> Dict:
        """t-test ë° ì‹ ë¢°êµ¬ê°„ì„ í†µí•œ í†µê³„ì  ìœ ì˜ì„± ê²€ì¦"""
        print(f"\n{'='*80}")
        print("3. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ (t-test + ì‹ ë¢°êµ¬ê°„)")
        print(f"{'='*80}")

        baseline_folds = self.baseline['cv_folds']
        phase1a_folds = np.array(self.phase1a_results['cv_folds'])

        baseline_mean = baseline_folds.mean()
        phase1a_mean = phase1a_folds.mean()
        baseline_std = baseline_folds.std(ddof=1)
        phase1a_std = phase1a_folds.std(ddof=1)

        n = len(baseline_folds)
        n_total = 2 * n

        # Paired t-test (ë™ì¼í•œ fold êµ¬ì¡°)
        diff = baseline_folds - phase1a_folds
        t_stat = diff.mean() / (diff.std(ddof=1) / np.sqrt(n)) if diff.std(ddof=1) > 0 else 0
        df = n - 1
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))  # ì–‘ì¸¡ ê²€ì •

        print(f"\n  Paired t-test ê²°ê³¼:")
        print(f"    t-statistic: {t_stat:.4f}")
        print(f"    df (ììœ ë„): {df}")
        print(f"    p-value (ì–‘ì¸¡): {p_value:.6f}")

        # ì‹ ë¢°ë„ íŒì •
        if p_value < 0.05:
            significance = "âœ… í†µê³„ì ìœ¼ë¡œ ìœ ì˜ (p < 0.05, 95% ì‹ ë¢°ë„)"
        elif p_value < 0.10:
            significance = "âš ï¸ ì•½í•œ ìœ ì˜ì„± (p < 0.10, 90% ì‹ ë¢°ë„)"
        else:
            significance = "âŒ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ (p >= 0.10)"

        print(f"    íŒì •: {significance}")

        # 95% ì‹ ë¢°êµ¬ê°„
        se_baseline = baseline_std / np.sqrt(n)
        se_phase1a = phase1a_std / np.sqrt(n)

        t_critical = stats.t.ppf(0.975, df)

        baseline_ci = [
            baseline_mean - t_critical * se_baseline,
            baseline_mean + t_critical * se_baseline
        ]
        phase1a_ci = [
            phase1a_mean - t_critical * se_phase1a,
            phase1a_mean + t_critical * se_phase1a
        ]

        print(f"\n  95% ì‹ ë¢°êµ¬ê°„:")
        print(f"    Baseline: [{baseline_ci[0]:.4f}, {baseline_ci[1]:.4f}]")
        print(f"    Phase 1-A: [{phase1a_ci[0]:.4f}, {phase1a_ci[1]:.4f}]")

        # ì‹ ë¢°êµ¬ê°„ ê²¹ì¹¨ ë¶„ì„
        if phase1a_ci[1] < baseline_ci[0]:
            overlap = "ì™„ì „ ë¶„ë¦¬ (Phase 1-Aê°€ ëª…ë°±íˆ ë” ë‚˜ìŒ)"
        elif phase1a_ci[0] > baseline_ci[1]:
            overlap = "ì™„ì „ ë¶„ë¦¬ (Phase 1-Aê°€ ëª…ë°±íˆ ë” ë‚˜ì¨)"
        elif abs(phase1a_ci[1] - baseline_ci[0]) < 0.01:
            overlap = "ê²½ê³„ì„  ìƒ ì ‘ì´‰ (ë§¤ìš° ìœ ì‚¬)"
        else:
            overlap_ratio = 1 - (max(0, baseline_ci[0] - phase1a_ci[1]) +
                                 max(0, phase1a_ci[0] - baseline_ci[1])) / \
                           (max(baseline_ci[1], phase1a_ci[1]) -
                            min(baseline_ci[0], phase1a_ci[0]))
            overlap = f"ë¶€ë¶„ ê²¹ì¹¨ ({overlap_ratio*100:.1f}%)"

        print(f"    ê²¹ì¹¨ ìƒíƒœ: {overlap}")

        # Effect Size (Cohen's d)
        pooled_std = np.sqrt(((n-1)*baseline_std**2 + (n-1)*phase1a_std**2) / (n_total - 2))
        cohen_d = (baseline_mean - phase1a_mean) / pooled_std if pooled_std > 0 else 0

        print(f"\n  Effect Size (Cohen's d): {cohen_d:.4f}")
        if abs(cohen_d) < 0.2:
            effect_interpretation = "ë§¤ìš° ì‘ì€ íš¨ê³¼"
        elif abs(cohen_d) < 0.5:
            effect_interpretation = "ì‘ì€ íš¨ê³¼"
        elif abs(cohen_d) < 0.8:
            effect_interpretation = "ì¤‘ê°„ íš¨ê³¼"
        else:
            effect_interpretation = "í° íš¨ê³¼"
        print(f"    í•´ì„: {effect_interpretation}")

        # ì‹ ë¢°ë„ ì ìˆ˜
        confidence_score = 0
        if p_value < 0.05:
            confidence_score = 95
        elif p_value < 0.10:
            confidence_score = 85
        else:
            confidence_score = max(50, 100 - int(p_value * 1000))

        stat_sig_result = {
            't_statistic': t_stat,
            'p_value': p_value,
            'significance': significance,
            'baseline_ci': baseline_ci,
            'phase1a_ci': phase1a_ci,
            'ci_overlap': overlap,
            'cohen_d': cohen_d,
            'effect_interpretation': effect_interpretation,
            'confidence_score': confidence_score,
            'is_significant': p_value < 0.05
        }

        return stat_sig_result

    # ========================================================================
    # 4. ì‹ ê·œ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    # ========================================================================

    def analyze_new_features(self) -> Dict:
        """ì‹ ê·œ 5ê°œ í”¼ì²˜ì˜ ì¤‘ìš”ë„ ë° ê¸°ì—¬ë„ ë¶„ì„"""
        print(f"\n{'='*80}")
        print("4. ì‹ ê·œ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
        print(f"{'='*80}")

        if self.phase1a_results is None:
            return {}

        new_features = self.phase1a_results.get('new_features', [])
        features_info = self.phase1a_results.get('features', {})

        print(f"\n  ì¶”ê°€ëœ í”¼ì²˜: {len(new_features)}ê°œ")
        print(f"  ì „ì²´ í”¼ì²˜: {features_info.get('total', 0)}ê°œ")
        print(f"    - ê¸°ì¡´: {features_info.get('existing', 0)}ê°œ")
        print(f"    - ì‹ ê·œ: {features_info.get('new', 0)}ê°œ")

        print(f"\n  ì‹ ê·œ í”¼ì²˜ë³„ ë¶„ì„:")

        feature_analysis = {}
        total_expected_contribution = 0

        for i, feat_name in enumerate(new_features, 1):
            if feat_name in self.new_features_info:
                feat_info = self.new_features_info[feat_name]
                importance = feat_info['importance_score']
                description = feat_info['description']
                business_value = feat_info['business_value']
                contribution = feat_info['expected_contribution']

                total_expected_contribution += contribution

                # ë³„ì  í‘œì‹œ
                stars = 'â­' * int(importance) + ('â—†' if importance % 1 == 0.5 else '')

                print(f"\n    {i}. {feat_name}")
                print(f"       ì¤‘ìš”ë„: {stars} {importance:.1f}/5.0")
                print(f"       ì„¤ëª…: {description}")
                print(f"       ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: {business_value}")
                print(f"       ê¸°ëŒ€ ê¸°ì—¬ë„: Â±{contribution:.3f}ì ")

                feature_analysis[feat_name] = {
                    'importance_score': importance,
                    'description': description,
                    'business_value': business_value,
                    'expected_contribution': contribution
                }

        print(f"\n  ì¢…í•© ë¶„ì„:")
        print(f"    ì´ ê¸°ëŒ€ ê°œì„ í­: Â±{total_expected_contribution:.3f}ì ")
        print(f"    ì˜ˆìƒ ë²”ìœ„: Â±{total_expected_contribution*0.8:.3f}ì  ~ Â±{total_expected_contribution*1.2:.3f}ì ")
        print(f"    í‰ê°€: ì‹ ê·œ í”¼ì²˜ë“¤ì´ ì•ˆì •ì ì¸ ê°œì„  ê°€ëŠ¥ì„± ì œì‹œ")

        feature_analysis['total_expected_contribution'] = total_expected_contribution

        return feature_analysis

    # ========================================================================
    # 5. ì œì¶œ ê²°ì • ê¸°ì¤€
    # ========================================================================

    def evaluate_submission_decision(self, cv_comparison: Dict,
                                     stat_sig: Dict,
                                     feature_analysis: Dict) -> Dict:
        """ì œì¶œ ê²°ì • ê¸°ì¤€ë³„ í‰ê°€"""
        print(f"\n{'='*80}")
        print("5. ì œì¶œ ê²°ì • ê¸°ì¤€ í‰ê°€")
        print(f"{'='*80}")

        cv_mean = self.phase1a_results['cv_mean']
        cv_std = self.phase1a_results['cv_std']
        cv_improvement = cv_comparison['cv_improvement']

        print(f"\n  í˜„ì¬ ìƒíƒœ:")
        print(f"    Phase 1-A CV: {cv_mean:.4f} Â± {cv_std:.4f}")
        print(f"    ê°œì„ í­: {cv_improvement:+.4f}")
        print(f"    í†µê³„ ìœ ì˜ë„: {'âœ…' if stat_sig['is_significant'] else 'âš ï¸'} "
              f"(p={stat_sig['p_value']:.4f})")

        print(f"\n  ê²°ì • ê¸°ì¤€ í‰ê°€:")

        # ê¸°ì¤€ 1: CV ì ˆëŒ€ê°’
        print(f"\n    1ï¸âƒ£ CV ì ˆëŒ€ê°’ í‰ê°€")
        if cv_mean < 15.50:
            rec1 = "ğŸš€ ê°•ë ¥ ì¶”ì²œ (CV < 15.50, ëª©í‘œ ë‹¬ì„±!)"
            score1 = 10
        elif cv_mean < 15.60:
            rec1 = "âœ… ì¡°ê±´ë¶€ ì¶”ì²œ (CV 15.50-15.60, ê°œì„  í™•ì¸)"
            score1 = 7
        elif cv_mean < 15.70:
            rec1 = "âš ï¸ ì¤‘ë¦½ (CV 15.60-15.70, ë¯¸ë¯¸í•œ ì•…í™”)"
            score1 = 3
        else:
            rec1 = "âŒ ì¬ê²€í†  í•„ìš” (CV > 15.70, ëª…ë°±í•œ ì•…í™”)"
            score1 = 0

        print(f"       {rec1}")
        print(f"       (ì ìˆ˜: {score1}/10)")

        # ê¸°ì¤€ 2: ê°œì„ í­
        print(f"\n    2ï¸âƒ£ ê°œì„ í­ í‰ê°€")
        if cv_improvement > 0.10:
            rec2 = "ğŸš€ ê°•ë ¥ ê°œì„  (> 0.10ì )"
            score2 = 10
        elif cv_improvement > 0.05:
            rec2 = "âœ… ì¤‘ê°„ ê°œì„  (0.05-0.10ì )"
            score2 = 8
        elif cv_improvement > 0.0:
            rec2 = "âœ… ì•½í•œ ê°œì„  (0-0.05ì )"
            score2 = 6
        elif cv_improvement >= -0.05:
            rec2 = "âš ï¸ ì¤‘ë¦½ (-0.05-0ì , ë¯¸ë¯¸í•œ ì•…í™”)"
            score2 = 3
        else:
            rec2 = "âŒ ì•…í™” (< -0.05ì )"
            score2 = 0

        print(f"       {rec2}")
        print(f"       (ì ìˆ˜: {score2}/10)")

        # ê¸°ì¤€ 3: ì•ˆì •ì„±
        print(f"\n    3ï¸âƒ£ ì•ˆì •ì„± í‰ê°€ (CV Std)")
        if cv_std < 0.15:
            rec3 = "ğŸ›¡ï¸ ë§¤ìš° ì•ˆì •ì  (Std < 0.15)"
            score3 = 10
        elif cv_std < 0.20:
            rec3 = "âœ… ì•ˆì •ì  (Std 0.15-0.20)"
            score3 = 8
        elif cv_std < 0.30:
            rec3 = "âš ï¸ ì¤‘ê°„ (Std 0.20-0.30)"
            score3 = 5
        else:
            rec3 = "âŒ ë¶ˆì•ˆì • (Std > 0.30)"
            score3 = 1

        print(f"       {rec3}")
        print(f"       (ì ìˆ˜: {score3}/10)")

        # ê¸°ì¤€ 4: í†µê³„ì  ìœ ì˜ì„±
        print(f"\n    4ï¸âƒ£ í†µê³„ì  ìœ ì˜ì„±")
        if stat_sig['is_significant'] and stat_sig['confidence_score'] >= 95:
            rec4 = "ğŸ¯ ë†’ì€ ì‹ ë¢°ë„ (p < 0.05, 95%)"
            score4 = 10
        elif stat_sig['confidence_score'] >= 85:
            rec4 = "âœ… ì¤‘ê°„ ì‹ ë¢°ë„ (p < 0.10, 90%)"
            score4 = 7
        elif stat_sig['confidence_score'] >= 70:
            rec4 = "âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (70-85%)"
            score4 = 4
        else:
            rec4 = "â“ ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ (< 70%)"
            score4 = 1

        print(f"       {rec4}")
        print(f"       (ì ìˆ˜: {score4}/10)")

        # ê¸°ì¤€ 5: ì‹ ê·œ í”¼ì²˜ ê¸°ì—¬ë„
        print(f"\n    5ï¸âƒ£ ì‹ ê·œ í”¼ì²˜ ê¸°ì—¬ë„")
        expected_contrib = feature_analysis.get('total_expected_contribution', 0)
        if cv_improvement > expected_contrib * 0.8:
            rec5 = "âœ… í”¼ì²˜ ê¸°ëŒ€ ì´ìƒì˜ ê°œì„ "
            score5 = 9
        elif cv_improvement > expected_contrib * 0.5:
            rec5 = "âœ… í”¼ì²˜ ê¸°ëŒ€ ì •ë„ì˜ ê°œì„ "
            score5 = 7
        elif cv_improvement > 0:
            rec5 = "âš ï¸ í”¼ì²˜ ê¸°ëŒ€ ì´í•˜ì˜ ê°œì„ "
            score5 = 4
        else:
            rec5 = "âŒ í”¼ì²˜ íš¨ê³¼ ë¯¸ë¯¸"
            score5 = 1

        print(f"       {rec5}")
        print(f"       (ì ìˆ˜: {score5}/10)")

        # ìµœì¢… ì¢…í•© ì ìˆ˜
        print(f"\n  {'='*60}")
        print(f"  ìµœì¢… ì¢…í•© ì ìˆ˜")
        print(f"  {'='*60}")

        total_score = (score1 + score2 + score3 + score4 + score5) / 5

        print(f"    CV ì ˆëŒ€ê°’: {score1}/10")
        print(f"    ê°œì„ í­: {score2}/10")
        print(f"    ì•ˆì •ì„±: {score3}/10")
        print(f"    í†µê³„ ìœ ì˜ì„±: {score4}/10")
        print(f"    í”¼ì²˜ ê¸°ì—¬ë„: {score5}/10")
        print(f"    {'â”€'*40}")
        print(f"    í‰ê·  ì ìˆ˜: {total_score:.1f}/10")

        # ìµœì¢… ê¶Œì¥ì‚¬í•­
        print(f"\n  {'='*60}")
        print(f"  ìµœì¢… ê¶Œì¥ì‚¬í•­")
        print(f"  {'='*60}")

        if total_score >= 8.0:
            final_recommendation = "ğŸš€ ê°•ë ¥ ì¶”ì²œ - ì§€ê¸ˆ ì œì¶œí•˜ì„¸ìš”!"
            confidence_level = "ë§¤ìš° ë†’ìŒ"
        elif total_score >= 6.5:
            final_recommendation = "âœ… ì¶”ì²œ - ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ë‚˜ìŒ"
            confidence_level = "ë†’ìŒ"
        elif total_score >= 5.0:
            final_recommendation = "âš ï¸ ì¤‘ë¦½ - ì¶”ê°€ ê²€í†  í›„ ê²°ì •"
            confidence_level = "ì¤‘ê°„"
        elif total_score >= 3.0:
            final_recommendation = "âš ï¸ ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ì‹œë„ - ë¦¬ìŠ¤í¬ ìˆìŒ"
            confidence_level = "ë‚®ìŒ"
        else:
            final_recommendation = "âŒ ë¯¸ê¶Œì¥ - ê¸°ì¡´ ëª¨ë¸ ìœ ì§€"
            confidence_level = "ë§¤ìš° ë‚®ìŒ"

        print(f"  {final_recommendation}")
        print(f"  ì‹ ë¢°ë„: {confidence_level}")

        submission_decision = {
            'cv_absolute_eval': rec1,
            'cv_improvement_eval': rec2,
            'stability_eval': rec3,
            'stat_significance_eval': rec4,
            'feature_contribution_eval': rec5,
            'final_recommendation': final_recommendation,
            'total_score': total_score,
            'confidence_level': confidence_level,
            'scores': {
                'cv_absolute': score1,
                'cv_improvement': score2,
                'stability': score3,
                'stat_significance': score4,
                'feature_contribution': score5
            }
        }

        return submission_decision

    # ========================================================================
    # 6. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    # ========================================================================

    def generate_comprehensive_report(self, cv_comparison: Dict,
                                      stat_sig: Dict,
                                      feature_analysis: Dict,
                                      decision: Dict) -> None:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œë¥¼ JSONê³¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥"""
        print(f"\n{'='*80}")
        print("6. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±")
        print(f"{'='*80}")

        # JSON ë³´ê³ ì„œ ìƒì„±
        report = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'experiment': 'Phase 1-A',
                'script': 'analyze_results.py'
            },
            'baseline': {
                'name': self.baseline['name'],
                'cv_mean': self.baseline['cv_mean'],
                'cv_std': self.baseline['cv_std'],
                'public_score': self.baseline['public_score'],
                'gap': self.baseline['gap']
            },
            'phase1a_results': {
                'cv_mean': self.phase1a_results['cv_mean'],
                'cv_std': self.phase1a_results['cv_std'],
                'cv_folds': self.phase1a_results['cv_folds'],
                'n_features': self.phase1a_results['features']['total'],
                'new_features': self.phase1a_results.get('new_features', [])
            },
            'analysis': {
                'cv_comparison': cv_comparison,
                'statistical_significance': {
                    't_statistic': stat_sig['t_statistic'],
                    'p_value': stat_sig['p_value'],
                    'is_significant': stat_sig['is_significant'],
                    'cohen_d': stat_sig['cohen_d'],
                    'confidence_score': stat_sig['confidence_score']
                },
                'feature_analysis': feature_analysis,
                'submission_decision': decision
            },
            'summary': {
                'final_recommendation': decision['final_recommendation'],
                'confidence_level': decision['confidence_level'],
                'total_score': decision['total_score']
            }
        }

        # JSON ì €ì¥
        json_file = self.results_dir / 'analysis_results.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"  âœ“ JSON ë³´ê³ ì„œ ì €ì¥: {json_file}")

        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
        markdown = self._generate_markdown_report(cv_comparison, stat_sig,
                                                   feature_analysis, decision)

        md_file = self.results_dir / 'ANALYSIS_RESULTS.md'
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(markdown)

        print(f"  âœ“ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì €ì¥: {md_file}")
        print(markdown)

    def _generate_markdown_report(self, cv_comparison: Dict,
                                  stat_sig: Dict,
                                  feature_analysis: Dict,
                                  decision: Dict) -> str:
        """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ë³´ê³ ì„œ"""

        baseline_mean = self.baseline['cv_mean']
        phase1a_mean = self.phase1a_results['cv_mean']
        cv_improvement = cv_comparison['cv_improvement']

        markdown = f"""# Phase 1-A ê²°ê³¼ ë¶„ì„ ë³´ê³ ì„œ

**ìƒì„±ì¼:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | ê¸°ì¡´ ëª¨ë¸ (exp_028) | Phase 1-A | ê°œì„  | í‰ê°€ |
|------|:---:|:---:|:---:|:---:|
| **CV Mean** | {baseline_mean:.4f} | {phase1a_mean:.4f} | {cv_improvement:+.4f} | {'âœ…' if cv_improvement > 0 else 'âŒ'} |
| **CV Std** | {self.baseline['cv_std']:.4f} | {self.phase1a_results['cv_std']:.4f} | {self.baseline['cv_std'] - self.phase1a_results['cv_std']:+.4f} | {'âœ…' if self.baseline['cv_std'] > self.phase1a_results['cv_std'] else 'âŒ'} |
| **Public** | {self.baseline['public_score']:.4f} | ì˜ˆìƒ {phase1a_mean:.4f} | ì˜ˆìƒ {cv_improvement:+.4f} | TBD |
| **Gap** | {self.baseline['gap']:.4f} | TBD | TBD | TBD |

### Foldë³„ ì„±ëŠ¥

| Fold | ê¸°ì¡´ | Phase 1-A | ê°œì„  |
|---:|:---:|:---:|:---:|
| 1 | {self.baseline['cv_folds'][0]:.4f} | {self.phase1a_results['cv_folds'][0]:.4f} | {self.baseline['cv_folds'][0] - self.phase1a_results['cv_folds'][0]:+.4f} |
| 2 | {self.baseline['cv_folds'][1]:.4f} | {self.phase1a_results['cv_folds'][1]:.4f} | {self.baseline['cv_folds'][1] - self.phase1a_results['cv_folds'][1]:+.4f} |
| 3 | {self.baseline['cv_folds'][2]:.4f} | {self.phase1a_results['cv_folds'][2]:.4f} | {self.baseline['cv_folds'][2] - self.phase1a_results['cv_folds'][2]:+.4f} |

---

## 2. ì‹ ê·œ í”¼ì²˜ ë¶„ì„

### ì¶”ê°€ëœ í”¼ì²˜ (5ê°œ)

| ìˆœë²ˆ | í”¼ì²˜ëª… | ì¤‘ìš”ë„ | ì„¤ëª… | ê¸°ëŒ€ íš¨ê³¼ |
|---:|---|:---:|---|:---:|
| 1 | **is_final_team** | â­â­â­â­â­ | ê³µê²©ê¶Œ í”Œë˜ê·¸ | Â±0.050ì  |
| 2 | **team_possession_pct** | â­â­â­â­ | ì ìœ ìœ¨ (20íŒ¨ìŠ¤) | Â±0.045ì  |
| 3 | **team_switches** | â­â­â­ | ê³µìˆ˜ ì „í™˜ íšŸìˆ˜ | Â±0.030ì  |
| 4 | **game_clock_min** | â­â­â­ | ê²½ê¸° ê²½ê³¼ ì‹œê°„ | Â±0.020ì  |
| 5 | **final_poss_len** | â­â­ | ì—°ì† ì†Œìœ  ê¸¸ì´ | Â±0.015ì  |

**ì´ ê¸°ëŒ€ ê°œì„ í­:** Â±{feature_analysis.get('total_expected_contribution', 0):.3f}ì 

---

## 3. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦

### t-test ê²°ê³¼

| í•­ëª© | ê°’ | í‰ê°€ |
|---|:---:|:---:|
| **t-statistic** | {stat_sig['t_statistic']:.4f} | - |
| **p-value** | {stat_sig['p_value']:.6f} | {'âœ… < 0.05' if stat_sig['p_value'] < 0.05 else 'âš ï¸ â‰¥ 0.05'} |
| **ì‹ ë¢°ë„** | {stat_sig['confidence_score']:.0f}% | {stat_sig['significance']} |
| **Cohen's d** | {stat_sig['cohen_d']:.4f} | {stat_sig['effect_interpretation']} |

### ì‹ ë¢°êµ¬ê°„ (95%)

- **Baseline:** [{stat_sig['baseline_ci'][0]:.4f}, {stat_sig['baseline_ci'][1]:.4f}]
- **Phase 1-A:** [{stat_sig['phase1a_ci'][0]:.4f}, {stat_sig['phase1a_ci'][1]:.4f}]
- **ê²¹ì¹¨ ìƒíƒœ:** {stat_sig['ci_overlap']}

---

## 4. ì œì¶œ ê²°ì • ê¸°ì¤€

### ê²°ì • ê¸°ì¤€ë³„ í‰ê°€

| ê¸°ì¤€ | í‰ê°€ | ì ìˆ˜ |
|---|---|:---:|
| CV ì ˆëŒ€ê°’ | {decision['cv_absolute_eval']} | {decision['scores']['cv_absolute']}/10 |
| ê°œì„ í­ | {decision['cv_improvement_eval']} | {decision['scores']['cv_improvement']}/10 |
| ì•ˆì •ì„± | {decision['stability_eval']} | {decision['scores']['stability']}/10 |
| í†µê³„ ìœ ì˜ì„± | {decision['stat_significance_eval']} | {decision['scores']['stat_significance']}/10 |
| í”¼ì²˜ ê¸°ì—¬ë„ | {decision['feature_contribution_eval']} | {decision['scores']['feature_contribution']}/10 |

### ìµœì¢… í‰ê°€

**ì¢…í•© ì ìˆ˜:** {decision['total_score']:.1f}/10

**ì‹ ë¢°ë„:** {decision['confidence_level']}

**ê¶Œì¥ì‚¬í•­:** {decision['final_recommendation']}

---

## 5. í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### ê°•ì  (Strengths)
- ì‹ ê·œ í”¼ì²˜ê°€ ë„ë©”ì¸ ì§€ì‹ì— ë¶€í•©
- CV ì•ˆì •ì„± ê°œì„  í™•ì¸
- 5ê°œ í”¼ì²˜ì˜ ì¢…í•© íš¨ê³¼ ê¸°ëŒ€

### ì•½ì  (Weaknesses)
- ê°œì„ í­ì´ ëª©í‘œì¹˜ ì´í•˜ì¼ ê°€ëŠ¥ì„±
- Gap ì •ë³´ ì—†ìŒ (Public Scoreì™€ì˜ ì°¨ì´ ë¶ˆí™•ì‹¤)
- ì‘ì€ ìƒ˜í”Œ í¬ê¸° (3-fold CV)

### ê¸°íšŒ (Opportunities)
- Phase 1-A ì„±ê³µ ì‹œ ì¶”ê°€ í”¼ì²˜ ê°œë°œ ê°€ëŠ¥
- ë‹¤ë¥¸ ëª¨ë¸ (XGBoost, LGBM ë“±)ê³¼ ì•™ìƒë¸” ê°€ëŠ¥
- í”¼ì²˜ ìƒí˜¸ì‘ìš© íƒìƒ‰

### ìœ„í˜‘ (Threats)
- Public Test Setì—ì„œ ë‹¤ë¥¸ ì„±ëŠ¥ (Gap í™•ëŒ€ ê°€ëŠ¥)
- í”¼ì²˜ ì˜¤ë²„í”¼íŒ… ê°€ëŠ¥ì„±
- ì œì¶œ ì œí•œ (í•˜ë£¨ 5íšŒ) ì œì•½

---

## 6. ì¶”ì²œ í–‰ë™ ê³„íš

### ì¦‰ì‹œ ì‹¤í–‰ (Step 1)
1. í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì¬í™•ì¸
2. cv_results.json ë°ì´í„° ê²€ì¦
3. ì‹ ê·œ í”¼ì²˜ì˜ NaN/ì´ìƒê°’ í™•ì¸

### ì œì¶œ ì „ (Step 2)
1. `train_final.py`ë¡œ ì „ì²´ ë°ì´í„°ì—ì„œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
2. `predict_test.py`ë¡œ ì œì¶œ íŒŒì¼ ìƒì„±
3. íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦

### DACON ì œì¶œ (Step 3)
1. submission_phase1a.csv ì—…ë¡œë“œ
2. ì œì¶œ ID ê¸°ë¡
3. SUBMISSION_LOG.md ì¦‰ì‹œ ì—…ë°ì´íŠ¸

### ê²°ê³¼ í‰ê°€ (Step 4)
1. Public Score í™•ì¸
2. Gap ê³„ì‚° (ì˜ˆìƒê°’ vs ì‹¤ì œê°’)
3. ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„
4. ë‹¤ìŒ ì‹¤í—˜ ë°©í–¥ ê²°ì •

---

## 7. ì£¼ì˜ì‚¬í•­

### ì¤‘ìš” (CRITICAL)
- **í•˜ë£¨ 5íšŒ ì œì¶œ ì œí•œ!** ì•ˆ ì“°ë©´ ì˜êµ¬ ì†Œì‹¤
- **SUBMISSION_LOG.mdëŠ” ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›** (í•­ìƒ ë¨¼ì € í™•ì¸)
- **Public Score â‰  CV Score** (Gap ë°œìƒ ê°€ëŠ¥)

### ì£¼ì˜ (WARNING)
- CV ê°œì„  â‰  ìˆœìœ„ í–¥ìƒ ë³´ì¥
- Private Test Setì—ì„œ ë‹¤ë¥¸ ì„±ëŠ¥ ê°€ëŠ¥
- Gapì´ í¬ë©´ ê³¼ì í•© ìš°ë ¤

### íŒ (TIPS)
- ë§¤ì¼ 5íšŒ ê¾¸ì¤€íˆ ì œì¶œí•˜ê¸°
- ì œì¶œ ê²°ê³¼ ì¦‰ì‹œ ê¸°ë¡í•˜ê¸°
- ì‹¤íŒ¨í•´ë„ í•™ìŠµìœ¼ë¡œ ì‚¼ê¸°

---

## 8. ë¬¸ì„œ ì°¸ê³ 

- **EXPERIMENT.md:** ìƒì„¸ ì‹¤í—˜ ì„¤ê³„
- **README.md:** ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
- **SUBMISSION_LOG.md:** ì œì¶œ ì´ë ¥ (í•„ë…!)

---

*Report generated by analyze_results.py (Phase 1-A Analysis Tool)*
"""

        return markdown

    # ========================================================================
    # 7. ë©”ì¸ ì‹¤í–‰
    # ========================================================================

    def run_full_analysis(self) -> bool:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print(f"\n{'='*80}")
        print("Phase 1-A ê²°ê³¼ ì¢…í•© ë¶„ì„ ì‹œì‘")
        print(f"{'='*80}")

        # Step 1: CV ê²°ê³¼ ë¡œë“œ
        if not self.load_cv_results():
            return False

        # Step 2: CV ë¹„êµ ë¶„ì„
        cv_comparison = self.compare_cv_performance()

        # Step 3: í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        stat_sig = self.statistical_significance_test(cv_comparison)

        # Step 4: ì‹ ê·œ í”¼ì²˜ ë¶„ì„
        feature_analysis = self.analyze_new_features()

        # Step 5: ì œì¶œ ê²°ì •
        decision = self.evaluate_submission_decision(cv_comparison, stat_sig, feature_analysis)

        # Step 6: ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        self.generate_comprehensive_report(cv_comparison, stat_sig, feature_analysis, decision)

        # ìµœì¢… ìš”ì•½
        print(f"\n{'='*80}")
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"{'='*80}")
        print(f"\n  ìµœì¢… ê¶Œì¥: {decision['final_recommendation']}")
        print(f"  ì‹ ë¢°ë„: {decision['confidence_level']}")
        print(f"  ì¢…í•© ì ìˆ˜: {decision['total_score']:.1f}/10")

        print(f"\n  ìƒì„±ëœ íŒŒì¼:")
        print(f"    - analysis_results.json")
        print(f"    - ANALYSIS_RESULTS.md")

        return True


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    import sys

    # ë””ë ‰í† ë¦¬ ì„¤ì •
    if len(sys.argv) > 1:
        results_dir = sys.argv[1]
    else:
        results_dir = str(Path(__file__).parent)

    # ë¶„ì„ ì‹¤í–‰
    analyzer = Phase1AResultsAnalyzer(results_dir=results_dir)
    success = analyzer.run_full_analysis()

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
